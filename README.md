# Toxic Comment Detection System

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)

The **Toxic Comment Detection System** is a machine learning-based project designed to automatically detect and classify toxic comments in online platforms. The system uses a Logistic Regression model with TF-IDF vectorization to classify comments into categories such as `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`.

---

## **Features**
- **Text Classification**: Detects toxic comments using machine learning.
- **Web Interface**: A user-friendly Flask-based web interface for inputting comments and viewing predictions.
- **Threshold Adjustment**: Allows users to adjust the classification threshold for better results.

---

## **Installation**
1. Clone the repository:
   ```bash
  
   cd toxic-comment-detection